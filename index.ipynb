{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import LSTM\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import linecache\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle as pkl\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = Path(r\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sample_data():\n",
    "    datapath = root_path/\"train_full.csv\"\n",
    "    train_df_iter = pd.read_csv(datapath, chunksize=500000, encoding=\"gbk\")\n",
    "    rand_list = [random.randint(0, 118042) for i in range(128)]\n",
    "    counter = 0\n",
    "    demo_df = pd.DataFrame()\n",
    "    for train_df in tqdm(train_df_iter):\n",
    "    #     print(train_df.head())\n",
    "    #     print(train_df[\"小区编号\"].unique())\n",
    "        counter += train_df.loc[train_df[\"小区编号\"].isin(rand_list)].shape[0]\n",
    "        demo_df = pd.concat([demo_df, train_df.loc[train_df[\"小区编号\"].isin(rand_list)]])\n",
    "    return demo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_filter(demo_df):\n",
    "    demo_df = demo_df.rename(columns={\"日期\": \"Date\", \"时间\":\"Time\", \"小区编号\":\"ID\", \"上行业务量GB\":\"Upload(GB)\", \"下行业务量GB\":\"Download(GB)\"})\n",
    "    mapping = {'018-04-01':\"2018/4/1\", '018-04-02':\"2018/4/2\", '018-04-03':\"2018/4/3\", '018-04-04':\"2018/4/4\", '018-04-08':\"2018/4/8\", '018-04-09':\"2018/4/9\", '018-04-10':\"2018/4/10\"}\n",
    "    demo_df[\"Date\"] = demo_df.Date.map(lambda x: x if x not in mapping else mapping[x])\n",
    "    demo_df[\"DateTime\"] = demo_df[\"Date\"] + ' '+demo_df[\"Time\"]\n",
    "    demo_df[\"DateTime\"] = pd.to_datetime(demo_df[\"DateTime\"])\n",
    "    demo_df = demo_df.set_index(\"DateTime\")\n",
    "    return demo_df\n",
    "# t_demo_df = data_filter(temp_demo_df)\n",
    "# t_demo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, name):\n",
    "    df.to_csv(root_path/name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data(demo=True):\n",
    "    test_path = root_path/(\"test_demo.csv\" if demo else \"train_test.csv\")\n",
    "    test_df = pd.read_csv(test_path, index_col=\"DateTime\")\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data(demo=True):\n",
    "    def gen_iter_df():\n",
    "        for g in root_path.glob(\"train_full_split_*.csv\"):\n",
    "            yield pd.read_csv(g, index_col=\"DateTime\")\n",
    "    if demo:\n",
    "        demo_path = root_path/(\"train_demo.csv\")\n",
    "        demo_df = pd.read_csv(demo_path, index_col=\"DateTime\")\n",
    "    else:\n",
    "        demo_df = gen_iter_df()\n",
    "        \n",
    "    return demo_df\n",
    "# demo_df = read_train_data()\n",
    "# demo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(df):\n",
    "    \"\"\"\n",
    "        能够从df直接出能够用来训练的数据\n",
    "        输出pad之后的数据和每个数据的长度，以及每个值都属于什么ID\n",
    "    \"\"\"\n",
    "    def padding(data):\n",
    "        max_length = 0\n",
    "        lengths = []\n",
    "        for item in data:\n",
    "            lengths.append(item.shape[0])\n",
    "        max_length = max(lengths)\n",
    "        data_new = np.array([np.concatenate([item, np.zeros((max_length-item.shape[0], item.shape[1]))]) for item in data])\n",
    "        return data_new, lengths\n",
    "    df = df.drop(df[(df[\"Upload(GB)\"].isna())|(df[\"Download(GB)\"].isna())].index)\n",
    "    assert df[\"Upload(GB)\"].isna().sum() == 0, \"Upload(GB) has nan\"\n",
    "    assert df[\"Download(GB)\"].isna().sum() == 0, \"Download(GB) has nan\"\n",
    "    data_df = df.sort_values(by=[\"ID\", \"DateTime\"])\n",
    "    index = []\n",
    "    data = []\n",
    "    final_df = pd.DataFrame()\n",
    "    for item in data_df[\"ID\"].unique():\n",
    "        item_df = data_df.loc[data_df[\"ID\"] == item]\n",
    "        index.append(item)\n",
    "        data.append(item_df.loc[:, [\"Upload(GB)\", \"Download(GB)\"]].values)\n",
    "#         data.append(item_df[\"Upload(GB)\"].tolist())\n",
    "    #     print(len(item_df[\"Upload(GB)\"].values))\n",
    "#         data_D.append(item_df[\"Download(GB)\"].tolist())\n",
    "    #     print(len(item_df[\"Download(GB)\"].values))\n",
    "    data_pad, data_lengths = padding(data)\n",
    "    return index, torch.Tensor(data_pad), data_lengths\n",
    "# index, data_pad, data_lengths = make_data(demo_df)\n",
    "# data_pad.shape, len(data_lengths), len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl.dump([\"index, data_pad_T, data_lengths\", index, data_pad_T, data_lengths], open(r\"D:\\Dataset\\MathorCup\\train_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, index, data_pad_T, data_lengths = pkl.load(open(r\"D:\\Dataset\\MathorCup\\train_data.pkl\", \"rb\"))\n",
    "# _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM模型必须需要三维\n",
    "- (batch_size, time_sequence, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathorCup(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_first=True, dropout=0.5, cuda=False, num_layers=2, cuda_card=0):\n",
    "        super(MathorCup, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.batch_first = batch_first\n",
    "        self.dropout = dropout\n",
    "        self.cuda = cuda\n",
    "        self.cuda_card = cuda_card\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "#         self.d_model = 512\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        if self.cuda:\n",
    "            torch.cuda.set_device(self.cuda_card)\n",
    "#             self.device = torch.device(\"cuda:{}\".format(self.cuda_card))\n",
    "#         self.linear = nn.Linear(self.input_size, self.d_model)\n",
    "        self.norm = nn.LayerNorm(self.input_size)\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=self.input_size, \n",
    "            hidden_size=self.hidden_size, \n",
    "            batch_first=self.batch_first, \n",
    "            dropout=self.dropout, \n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "        self.linear_h = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.linear_c = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.eval_decoder = nn.LSTMCell(\n",
    "            input_size=self.input_size, \n",
    "            hidden_size=self.hidden_size, \n",
    "            bias=True\n",
    "        )\n",
    "        self.train_decoder = nn.LSTM(\n",
    "            input_size=self.input_size, \n",
    "            hidden_size=self.hidden_size, \n",
    "            batch_first=self.batch_first, \n",
    "            dropout=self.dropout, \n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "        self.output = nn.Linear(in_features=self.hidden_size, out_features=self.output_size)\n",
    "        if self.cuda:\n",
    "            self.norm = self.norm.cuda()\n",
    "            self.encoder = self.encoder.cuda()\n",
    "            self.linear_h = self.linear_h.cuda()\n",
    "            self.linear_c = self.linear_c.cuda()\n",
    "            self.train_decoder = self.train_decoder.cuda()\n",
    "            self.eval_decoder = self.eval_decoder.cuda()\n",
    "            self.output = self.output.cuda()\n",
    "    \n",
    "    def encode(self, x):\n",
    "        if self.cuda:\n",
    "            x = x.cuda()\n",
    "        x = self.norm(x)\n",
    "#         print(x.shape)\n",
    "#         x = self.linear(x)\n",
    "#         y = self.linear(y)\n",
    "#         print(x.shape)\n",
    "#         x = x.permute(1, 0, 2)\n",
    "#         y = y.permute(1, 0, 2)\n",
    "#         out = self.transformer(x, y)\n",
    "#         out = out.permute(1, 0, 2)\n",
    "#         print(x.mean())\n",
    "        o, (h, c) = self.encoder(x)\n",
    "        \n",
    "        return o, (h, c)\n",
    "    \n",
    "    def attention(self, o, y):\n",
    "        return torch.zeros_like(y)\n",
    "    \n",
    "    def train_decode(self, y, h_c):\n",
    "        if self.cuda:\n",
    "            y = y.cuda()\n",
    "        out, h_c = self.train_decoder(y, h_c)\n",
    "        outputs = self.output(out)\n",
    "        return outputs\n",
    "    \n",
    "    def evaluate_decode(self, y_t, h_c, num):\n",
    "        # 这里比纯lstm慢太多了\n",
    "        if self.cuda:\n",
    "            y_t = y_t.cuda()\n",
    "        h, c = h_c\n",
    "        outputs = []\n",
    "        for i in range(num):\n",
    "#             y_t = torch.squeeze(y_t, dim=1)\n",
    "            h, c = self.linear_h(h), self.linear_c(c)\n",
    "            h, c = torch.squeeze(h, dim=0), torch.squeeze(c, dim=0)\n",
    "            \n",
    "            h, c = self.eval_decoder(y_t, (h, c))\n",
    "            out = self.output(h)\n",
    "            y_t = out\n",
    "            outputs.append(out)\n",
    "        outputs = torch.stack(outputs, dim=0).permute(1, 0, 2)\n",
    "        return outputs\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        self.train()\n",
    "        o, (h, c) = self.encode(x)\n",
    "#         att = self.attention(o, y)\n",
    "        \n",
    "        out = self.train_decode(y, (h, c))\n",
    "        return out.cpu()\n",
    "#         o1 = self.output(x1)\n",
    "#         return o1.cpu()\n",
    "    def evaluate(self, x, num):\n",
    "        self.eval()\n",
    "        o, (h, c) = self.encode(x)\n",
    "        out = self.evaluate_decode(x[:, -1, :], (h, c), num)\n",
    "        return out.cpu()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "mc = MathorCup(2, 128, 2, cuda=True, num_layers=5, cuda_card=5)\n",
    "summary(mc, ((128, 13, 2), (128, 4, 2)), batch_dim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sample(data, lengths, index, offset=None):\n",
    "    \"\"\"\n",
    "        使用前5个小时，一天前的4个小时，两天前的2个小时，一周前的2个小时进行预测\n",
    "    \"\"\"\n",
    "    if offset == None:\n",
    "        offset = [-1, -2, -3, -4, -5, -24, -25, -26, -27, -48, -49, -168, -169]\n",
    "        offset.reverse()\n",
    "    mini_offset = min(offset)\n",
    "    selected = [index+item if index+item >= 0 else -1 for item in offset]\n",
    "    pred = [index+item+1 if index+item >= 0 else -1 for item in offset]\n",
    "#     print(pred[-1])\n",
    "    data_samp = torch.stack([data[:, item, :] if item >=0 else torch.zeros_like(data[:, item, :]) for item in selected], dim=1)\n",
    "    data_pred = torch.stack([data[:, item, :] if item >=0 else torch.zeros_like(data[:, item, :]) for item in pred], dim=1)\n",
    "#     data_pred = data[:, [index], :]\n",
    "#     return data_samp, data_pred\n",
    "    return data_samp, data_pred\n",
    "# data_samp, data_pred = data_sample(data_pad_T, data_lengths, 0)\n",
    "# data_samp, data_pred = data_sample(data_pad, data_lengths, 16)\n",
    "# data_samp.shape, data_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, data_pad, lengths = make_data(read_train_data())\n",
    "len(index), data_pad.shape, len(lengths)\n",
    "# data_samp, data_pred = data_sample(data_pad, lengths, 2, )\n",
    "# data_samp.shape, data_pred.shape\n",
    "# mc(data_samp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(data_pad, split_size, lengths, batch_size):\n",
    "    total_num = data_pad.shape[1]\n",
    "    train_num = int(total_num*split_size)\n",
    "    val_num = total_num - train_num\n",
    "    train_data_pad, train_lengths = data_pad[:, :train_num, :], [train_num if item > train_num else item for item in lengths]\n",
    "    val_data_pad, val_lengths = data_pad[:, train_num:, :], [item-train_num if item > train_num else 0 for item in lengths] # 可能出负数，但是一般不会\n",
    "    torch_Dataset = torch.utils.data.TensorDataset(train_data_pad, val_data_pad)\n",
    "    loader = torch.utils.data.DataLoader(dataset=torch_Dataset, batch_size=batch_size, shuffle=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(df, cuda=True, cuda_card=0, epoch=5, lr=0.01, clip_value=0.001, hidden_num=32, log_per=1000, eval_per=100, num_layers=1, split_size=0.6, batch_size=32):\n",
    "    train_mode = False\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        train_mode = True\n",
    "    lr_thresh = lr * 0.01\n",
    "    mc = MathorCup(2, hidden_num, 2, cuda=cuda, cuda_card=cuda_card, num_layers=num_layers)\n",
    "#     mc = nn.DataParallel(mc, output_device=[8])\n",
    "    optim = torch.optim.Adam(mc.parameters(), lr=lr)\n",
    "#     scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, lr_lambda=[lambda epoch: 0.9*epoch])\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, 0.99)\n",
    "    loss_func = nn.MSELoss()\n",
    "    \n",
    "    if not train_mode:\n",
    "        df = [df]\n",
    "    \n",
    "    counter = 0\n",
    "    local_loss = []\n",
    "    cum_loss = []\n",
    "    for epo in range(epoch):\n",
    "        for d in df:\n",
    "            index, data_pad, lengths = make_data(d)\n",
    "            # 创建dataloader\n",
    "            loader = make_loader(data_pad, split_size, lengths, batch_size)\n",
    "            for step, (batch_train, batch_val) in enumerate(loader):\n",
    "                counter += 1\n",
    "#                 print(counter)\n",
    "    #             print(step, batch_train.shape, batch_val.shape)\n",
    "                batch_val_inp = batch_val[:, :-1, :]\n",
    "                batch_val_real = batch_val[:, 1:, :]\n",
    "                out = mc(batch_train, batch_val_inp)\n",
    "#                 print(out.mean(), batch_val_real.mean())\n",
    "                loss = loss_func(out, batch_val_real)\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                # 剪裁\n",
    "                torch.nn.utils.clip_grad_value_(mc.parameters(), clip_value)\n",
    "                optim.step()\n",
    "                local_loss.append(loss.item())\n",
    "                if math.isnan(loss.item()):\n",
    "                    print(f\"nan Counter: {counter+1}, index: {out.isnan()}\")\n",
    "                    break\n",
    "                if (counter+1) % log_per == 0:\n",
    "                    print(f\"Epoch:{epo}, Counter:{counter+1}, Local Loss:{np.mean(local_loss)}\")\n",
    "                    cum_loss.append(np.mean(local_loss))\n",
    "                    local_loss = []\n",
    "                if (counter+1) % eval_per == 0:\n",
    "                    eval_out = mc.evaluate(batch_train, batch_val.shape[1])\n",
    "                    eval_loss = loss_func(eval_out, batch_val)\n",
    "                    print(f\"Epoch:{epo}, Counter:{counter+1}, Eval Loss:{eval_loss.item()}\")\n",
    "    #         if lr > lr_thresh:\n",
    "    #             scheduler.step()\n",
    "            \n",
    "            lr = optim.state_dict()['param_groups'][0]['lr']\n",
    "            if (epo+1) % 50 == 0:\n",
    "                print(lr)\n",
    "                \n",
    "    #         if (epo+1) % 200 == 0:\n",
    "    #             optim = torch.optim.Adamax(mc.parameters(), lr = optim.state_dict()['param_groups'][0]['lr'])\n",
    "    #             scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=[lambda epoch: 0.1*epoch])\n",
    "    #         for index in range(data_pad.shape[1]):\n",
    "    #             counter += 1\n",
    "    #             data_samp, data_pred = data_sample(data_pad, lengths, index, )\n",
    "    #             output = mc(data_samp)\n",
    "    #             loss = loss_func(output, data_pred)\n",
    "    #             optim.zero_grad()\n",
    "    #             loss.backward()\n",
    "    #             # 剪裁\n",
    "    # #             torch.nn.utils.clip_grad_value_(mc.parameters(), clip_value)\n",
    "    #             optim.step()\n",
    "    #             local_loss.append(loss.item())\n",
    "    #             cum_loss.append(loss.item())\n",
    "    #             if math.isnan(loss.item()):\n",
    "    #                 print(f\"nan Counter: {counter+1}, index: {index}\")\n",
    "    #                 break\n",
    "    #             if (counter+1) % log_per == 0:\n",
    "    #                 print(f\"Epoch:{epo}, Counter:{counter+1}, Local Loss:{np.mean(local_loss)}\")\n",
    "    #                 local_loss = []\n",
    "    #         scheduler.step()\n",
    "    return mc, cum_loss\n",
    "# mc = train(demo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, df, split_size=0.6, batch_size=16):\n",
    "    index, data_pad, lengths = make_data(df)\n",
    "    loader = make_loader(data_pad, split_size, lengths, batch_size)\n",
    "    plot_list = []\n",
    "    max_test = 100\n",
    "    for step, (batch_train, batch_val) in enumerate(loader):\n",
    "#         batch_val_inp = batch_val[:, :-1, :]\n",
    "#         batch_val_real = batch_val[:, 1:, :]\n",
    "        out = model.evaluate(batch_train, batch_val.shape[1])\n",
    "#         print(out.shape, batch_val_real.shape)\n",
    "#         plot_list.append((out[-1, :, :], batch_val_real[-1, :, :]))\n",
    "        plot_list.append((out[-1, :, :], batch_val[-1, :, :]))\n",
    "#     for index in tqdm(range(max(data_pad.shape[1], max_test))):\n",
    "#         data_samp, data_pred = data_sample(data_pad, lengths, index, )\n",
    "#         output = model(data_samp)\n",
    "#         plot_list.append((output[:, -1, :], data_pred[:, -1, :]))\n",
    "    return plot_list\n",
    "\n",
    "# plot_list = test(mc, t_demo_df)\n",
    "# plot_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_plot(plot_list, sample_id=None, plot_range=None):\n",
    "    if sample_id==None:\n",
    "        sample_id = random.randint(0, 127)\n",
    "    if plot_range==None:\n",
    "        temp = random.randint(0, 300)\n",
    "        plot_range = [temp, temp+100]\n",
    "    print(sample_id)\n",
    "    print(plot_range)\n",
    "    new_plot = torch.stack([torch.stack(item) for item in plot_list])\n",
    "    print(new_plot.shape)\n",
    "    Upload_x = new_plot[-1, 0, :, 0].detach().numpy()\n",
    "    Upload_y = new_plot[-1, 1, :, 0].detach().numpy()\n",
    "    \n",
    "    Download_x = new_plot[-1, 0, :, 1].detach().numpy()\n",
    "    Download_y = new_plot[-1, 1, :, 1].detach().numpy()\n",
    "    # new_plot_x.shape\n",
    "    fig, ax = plt.subplots(2, 1, squeeze=False)\n",
    "    ax[0][0].plot(Upload_x[plot_range[0]:plot_range[1]])\n",
    "    ax[0][0].plot(Upload_y[plot_range[0]:plot_range[1]], color='red', linestyle=\"--\")\n",
    "    ax[0][0].legend([\"Raw\", \"Pred\"])\n",
    "    ax[0][0].set_title(f\"Upload(GB) Prediction Plot From {plot_range[0]} To {plot_range[1]} In Sample {sample_id}\")\n",
    "    ax[1][0].plot(Download_x[plot_range[0]:plot_range[1]])\n",
    "    ax[1][0].plot(Download_y[plot_range[0]:plot_range[1]], color='red', linestyle=\"--\")\n",
    "    ax[1][0].legend([\"Raw\", \"Pred\"])\n",
    "    ax[1][0].set_title(f\"Download(GB) Prediction Plot From {plot_range[0]} To {plot_range[1]} In Sample {sample_id}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "# new_plot_x.detach().numpy()\n",
    "# fig = sample_plot(plot_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(demo=True):\n",
    "    print(\"Reading Test Data...\")\n",
    "    try:\n",
    "        test_df = read_test_data(demo)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Start Sampling...(About 3 mins)\")\n",
    "        test_df = data_filter(sample_data())\n",
    "        save_df(test_df, \"test_demo.csv\")\n",
    "    print(\"Reading Train Data...\")\n",
    "    try:\n",
    "        train_df = read_train_data(demo)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Start Sampling...(About 3 mins)\")\n",
    "        train_df = data_filter(sample_data())\n",
    "        save_df(train_df, \"train_demo.csv\")\n",
    "    print(\"Training...\")\n",
    "    mc, cum_loss = train(train_df, cuda=True, cuda_card=0, epoch=600, lr=0.01, clip_value=0.001, hidden_num=128, log_per=100, eval_per=1000, num_layers=5, batch_size=16)\n",
    "    print(\"Testing\")\n",
    "    plot_list = None\n",
    "    plot_list = test(mc, test_df)\n",
    "    return plot_list, cum_loss, mc\n",
    "plot_list, cum_loss, mc = main(demo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sample_plot(plot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(cum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = sum([np.prod(list(p.size())) for p in mc.parameters()])\n",
    "str(para/1000/1000)+\"MB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = data_pad[:32, :660, :]\n",
    "input_.requires_grad_(requires_grad=False)\n",
    "print(input_.shape)\n",
    "mods = list(mc.modules())\n",
    "out_sizes = []\n",
    "for i in range(1, len(mods)):\n",
    "    m = mods[i]\n",
    "    print(m)\n",
    "    out = m(input_)\n",
    "    out_sizes.append(np.array(out.size()))\n",
    "    input_ = out\n",
    "mods[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“pytorch”",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
